---
title: 'OHI-Northeast: Sea Level Rise Pressure Layer'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ohi-northeast/src/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---

#Summary  
The sea level rise pressure layer is derived from monthly data of gridded sea level anomalies from 1993 to present. The gridded data is clipped to three nautical miles of the coastline in the US Northeast region and aggregated to annual means. All data is rescaled from 0 to 1 using the maximum annual anomaly across the time series as the reference point.

***

#Data Source  
**Reference**: AVISO [Monthly mean Maps of Sea Level Anomaly](http://www.aviso.altimetry.fr/en/data/products/sea-surface-height-products/global/msla-mean-climatology.html#c10358)

**Downloaded**: September 16, 2016

**Description**:  Mean Sea Level Anomaly (m above a climatological mean)

**Native data resolution**: 0.25 degree cells

**Time range**: 1993 - 2015, monthly data provided for each year

**Format**:  NetCDF

***
  
#Methodsgit rm --cached -r .

## Setup

``` {r setup, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 10, fig.height = 8, fig.path = 'figs/', message = FALSE, warning = FALSE)

#setwd("~/github/ne-prep/prep/pressures/slr") 

source('~/github/ne-prep/src/R/common.R')  ### an OHI-NE specific version of common.R

## setting up provenance
# devtools::install_github('oharac/provRmd')
# library(provRmd)
# prov_setup()

#if we want to include the loading of all these packages into the markdown
#pkg <- c( "httr", "R.utils", "raster", "tidyverse", "sf", "RColorBrewer", "ggplot2", "googleVis",
#          "maps", "parallel", "foreach", "doParallel", "fasterize", "rasterVis")
#new.pkg <- pkg[!(pkg %in% installed.packages())]
#if (length(new.pkg)){install.packages(new.pkg)}
#lapply(pkg, require, character.only = TRUE)

library(httr)
library(R.utils)
library(raster)
library(tidyverse)
library(sf)
library(RColorBrewer)
library(ggplot2)
library(googleVis)
library(maps)
library(parallel)
library(foreach)
library(doParallel)
library(fasterize)
library(rasterVis)
library(here)
library(raster)
```


```{r}
## define paths and variables to use throughout data prep
 
#scen_year <- 2019 # change to reflect assessment year!
#dir_anx_aviso <- file.path(dir_M, "git-annex/globalprep/_raw_data/AVISO_slr") # raw data file path
#dir_prs_slr <-  sprintf("%s/git-annex/globalprep/prs_slr/v%s", dir_M, scen_year)

dir_git <- '~/github/ne-prep'
dir_anx <- file.path(dir_M, 'git-annex/neprep')

p4s_wgs84 <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0" # proj4string
us_alb    <- "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs"

cols <- rev(colorRampPalette(brewer.pal(9, "Spectral"))(255)) # rainbow color scheme for maps
us_albersCRS <- CRS("+proj=aea") # us albers projection, double check

## read in ocean raster with cells at 1km -- template for resampling (held on an NCEAS server)
## need to reproject to us albers and crop to our region 
#ocean <- raster(file.path(dir_M, "git-annex/globalprep/spatial/v2017/ocean.tif")) %>% 
#  projectRaster(crs = us_alb, over = FALSE, progress="text") %>% 
#  raster::crop(ne_ext)
#plot(ocean) #check that it worked
#WRITE RASTER SO I DONT HAVE TO DO THIS AGAIN

#ne_ext <- raster::extent(1750000, 2550000,300000,1200000) #shouldn't need this here, it should be in source(common.R)

```


#data_prep

Don't need to download the data again, because it's already been downloaded for the most recent year of global

Grab the NetCDF files from the global folder.
```{r}
## d2016/msla_monthly_mean has data for 1993-2015
## then include list.files for d2017 through the data folder for current scenario year
nc_files <- c(list.files(file.path(dir_M, "git-annex/globalprep/_raw_data/AVISO_slr/d2019"),
                       full.names = TRUE, pattern = ".nc"),
              list.files(file.path(dir_M, "git-annex/globalprep/_raw_data/AVISO_slr/d2018"),
                       full.names = TRUE, pattern = ".nc"),
              list.files(file.path(dir_M, "git-annex/globalprep/_raw_data/AVISO_slr/d2017"),
                       full.names = TRUE, pattern = ".nc"),
              list.files(file.path(dir_M, "git-annex/globalprep/_raw_data/AVISO_slr/d2016/msla_monthly_mean"),
                      full.names = TRUE, pattern = ".nc"))

nc_files <- nc_files[-1:-2] # double check this, but it since the first two files are zip files I am confident in removing them. However, I did grab it directly from the most recent version of global so I so still want to make sure it's correct
```

A peak into what the monthly data looks like
```{r}
plot(raster(nc_files[3]), col = cols, axes = F, 
     main = paste("Year", substr(nc_files[3], 90, 93), "Month", substr(nc_files[3], 96, 97)))
```


The following code is used to:

1. Rasterize each monthly NetCDF file
2. Rotate each raster so that the Atlantic Ocean is centered in the raster

The output is saved in the folder int/msla_monthly

```{r}
registerDoParallel(10)
## parallel forloop function that rotates each monthly file, sets the long/lat projection, and keeps only coastal cells - saved to GitHub

foreach(file = nc_files) %dopar% {
  
  m_yr <- substr(file, nchar(file)-10, nchar(file)-3) 
  
  ## read in month raster
  r <- raster(file) %>% 
    rotate()
  
  ## define projection of the raster before reprojecting; double check projection (USA Contiguous albers equal area)
  
  r <- raster::crop(r, wgs_ext)
  
  ## write raster to int folder in prs_slr
  fp <- sprintf("%s/int/msla_monthly/msla_monthly_%s.tif", file.path(dir_anx, "prs_slr"), m_yr)
  writeRaster(r, filename = fp, overwrite = TRUE)
}

```

Calculate the annual mean sea level anomalies
Annual mean sea level anomaly rasters are calculated from the monthly data.

```{r}
msla_files <- list.files(sprintf("%s/int/msla_monthly", file.path(dir_anx, "prs_slr")), 
                         full.names = TRUE)
maxyr <- substr(msla_files, 73, 76) %>% as.numeric() %>% max()

## stack all rasters for this year, and calc annual mean, then write as raster
registerDoParallel(6)
foreach(yr = c(1993:maxyr)) %dopar% {
  
  files <- msla_files[str_detect(msla_files, as.character(yr))]
  
  rast_annual_mean <- stack(files) %>%
    calc(mean, na.rm = TRUE) %>%
    writeRaster(filename = sprintf("%s/int/msla_annual_mean/msla_annual_%s.tif", file.path(dir_anx, "prs_slr"), yr), 
                overwrite = TRUE)
}
```


Changing the projection and masking
Since we are only interested in the increase in sea level near the coasts, we apply a mask to the raster layers that removes all cells farther than 3nm offshore. This mask was created previously for another part of this assessment

```{r}
three_nm <- raster(file.path(dir_git, "spatial/ocean_rasters/rast_3nm_mask.tif"))
three_nm <- raster::crop(three_nm, ne_ext)
plot(three_nm)

#reproject means to us albers

annual_means <- list.files(file.path(dir_anx, "prs_slr/int/msla_annual_mean"), full = TRUE)
foreach(file = annual_means) %dopar% {  
  
 # file = annual_means[26]
  yr <- str_sub(file, -8, -5)
  
  rast_data <- raster(file) %>%
    projectRaster(crs = us_alb, over = FALSE, progress="text") %>%
    raster::resample(three_nm, method = "ngb", 
             filename = sprintf("%s/prs_slr/int/msla_annual_us_albers/mlsa_annual_us_albers_%s.tif", 
                                dir_anx, yr), overwrite = TRUE) %>% 
    mask(three_nm, filename = sprintf("%s/prs_slr/int/msla_annual_us_albers_coastal/msla_annual_us_albers_coastal_%s.tif", dir_anx, yr), overwrite = TRUE)
}

plot(raster(file.path(dir_anx, "prs_slr/int/msla_annual_us_albers_coastal/msla_annual_us_albers_coastal_2010.tif")))
```

Reference Point
The reference point is the 99.99th quantile of the entire data distribution from 1993 - 2018. (This value has been updated due to changes in the source data, previously was 0.246225 m, currently is 0.3359385 m).

Here we are calculating a reference point specific to the Northeast. Will need to discuss if we want that, or use global's reference point (however I can't find the reference_points_pressures.csv it's in)

```{r}
coastal_rasts <- list.files(file.path(dir_anx, "prs_slr/int/msla_annual_us_albers_coastal"), pattern = "tif", full.names = TRUE)

registerDoParallel(8)

vals <- foreach(i = 1993:2018, .combine = c) %dopar% { 
  
  i=2018
  coastal_rasts[which(str_sub(coastal_rasts, -8, -5) == i)] %>%
    raster() %>%
    getValues() %>%
    na.omit()
  
}

ref <- quantile(vals, 0.9999)

```


Rescale
```{r}
registerDoParallel(10) 

foreach(file = coastal_rasts) %dopar% { #file = coastal_rasts[10]
  yr <- str_sub(file, -8,-5)

    raster::raster(file) %>%
    calc(fun = function(x){ifelse(x < 0, 0, x)}) %>% # set all negative values to 0
    calc(fun = function(x){ifelse(x > ref, 1, x/ref)}, # set equal to one if greater than ref, otherwise scale
         filename = sprintf("%s/prs_slr/output/slr_%s.tif", dir_anx, yr), overwrite = TRUE)
    
}
```

Results
```{r}
rasts <- list.files(file.path(dir_anx, "prs_slr/output"), full.names = TRUE) %>% str_subset(pattern = ".tif$")
stack_slr <- stack(rasts) # read in raster files
#zones <- raster(rgns) #might be able to just use the polygon
#plot(zones$rgn_name)

#just copied this in
rgn_data <- read_sf(file.path(dir_M, "git-annex/globalprep/spatial/v2017"), "regions_2017_update") %>%
  st_set_geometry(NULL) %>%
  dplyr::filter(rgn_type == "eez") %>%
  dplyr::select(rgn_id = rgn_ant_id, rgn_name)




```




To do:
Double check this markdown, and make sure it's all good
delete markdown "pressure_layer_slr_prep.Rmd" and rename this one that
delete output folders "msl_annual_mean, msla_annual_rescaled, msla_montly_coast" those are in an int folder now



