---
title: "Sediment Quality Index data layer"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ne-prep/src/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---

## Summary

This layer is derived from the EPA's National Coastal Condition Assessment Sediment Quality Index data.


```{r setup, message = F, warning = F, reslts = 'hide'}
knitr::opts_chunk$set(fig.width = 10, fig.height = 6, fig.path = 'figs/', message = FALSE, warning = FALSE)

source('~/github/ne-prep/src/R/common.R')

library(tidyverse)
```

## Load Sediment Quality Index data

There are two Sediment Quality Index datasets we are going to use for the two different time periods. 
I want to select only the information I need (states in our region and Water Quality Index categories). I also load the site info for each time series - we use the weights in each of these datasets.


This data was emailed to us on August 27, 2018. 

> "I have attached a file with Sediment Quality Index (NCCA_SQI_STATUS) good/fair/poor values merged with the site information file you have already downloaded."

Load then filter for the 2005-2006 years and our region.

#### 2005-2006 data

```{r}
sqi_0506 <- read.csv("data/NCA0506_SQI+siteinfo.csv") %>%
  filter(SAMPYEAR %in% c(2005,2006),
         NCA_REGION == "East_Coast",
         PSTL_CODE %in% c("MA", "ME", "RI", "NY", "NH", "CT")) %>%
  select(siteID = SITE_ID, LON_DD, LAT_DD, PSTL_CODE, WGT_NCA_56, NCCA_SQI_STATUS) %>%
  mutate(Year = 2006)
```

#### 2010 data

```{r}
site_info_2010 <- read_csv(file.path(dir_anx, "_raw_data/EPA/assessed_ncca2010_siteinfo.revised.06212016.csv")) %>%
  filter(STATE %in% c("MA", "ME", "RI", "NY", "NH", "CT"),
         NCA_REGION == "East Coast") %>%
  select(SITE_ID, WGT_NCCA10)

sqi_2010 <- read_csv(file.path(dir_anx, "_raw_data/EPA/ncca2010_sediment_indicator_status_revised_06212016.csv")) %>%
  filter(PSTL_CODE %in% c("MA", "ME", "RI", "NY", "NH", "CT"),
         NCCA_REG == "Northeast") %>%
  select(SITE_ID, NCCA_SQI_STATUS, LON_DD, LAT_DD, PSTL_CODE) %>%
  mutate(Year = 2010) %>%
  left_join(site_info_2010) %>%
  rename(siteID = SITE_ID)
```

## Data wrangling

I also need to assign regions to each of these. For the most part, the State is the region but for Massachusetts we need to be specific to what region it belongs. The best way to do this is manually.

```{r ma}
ma <- sqi_0506 %>%
  bind_rows(sqi_2010) %>%
  filter(PSTL_CODE == "MA")

ma_points = st_as_sf(ma, coords = c("LON_DD", "LAT_DD"), 
                 crs = 4326)

mapview::mapview(ma_points) 

ggplot() +
  geom_sf(data = rgns %>% filter(rgn_id %in% c(7,8)), aes(fill = rgn_id)) +
  geom_sf(data = ma_points, color = 'darkgreen') +
  theme_bw()

#try an st_intersect

int <- ma_points %>%
  st_transform('+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs') %>%
  st_intersection(rgns)

ggplot() +
  geom_sf(data = rgns %>% filter(rgn_id %in% c(7,8)), aes(fill = rgn_id)) +
  geom_sf(data = int, color = 'darkgreen') +
  theme_bw()
#mapview::mapview(int)
```

What points are we missing
```{r}
s <- setdiff(ma_points$siteID, int$siteID)

miss <- ma_points %>%
  filter(siteID %in% s)

mapview::mapview(miss)

#add a rgn_id column manually for the missing points based on mapview
miss_gf <- miss %>%
  data.frame() %>%
  mutate(rgn_id = 
           case_when(
             siteID == "NCCA10-1023" ~ 7,
             siteID == "MA05-0006" ~ 7,
             siteID == "MA06-0048" ~ 7,
             siteID == "MA06-0026" ~ 8,
             siteID == "NCCA10-1009" ~ 8,
             siteID == "MA06-0042" ~ 8,
             siteID == "NCCA10-1011" ~ 8,
             siteID == "MA05-0009" ~ 8,
             siteID == "NCCA10-1001" ~ 8,
             siteID == "NCCA10-1058" ~ 8,
             siteID == "NCCA10-1008" ~ 8,
             siteID == "NCCA10-2001" ~ 8,
             siteID == "RI05-0025" ~ 8
           )) %>%
  select(-geometry)
```

Take the info from `int` that we want and combine with these missing sites

```{r}
ma_df <- int %>%
  data.frame() %>%
  select(-area_km2, -geometry, -rgn_name) %>%
  bind_rows(miss_gf) %>%
  left_join(rgn_data) %>%
  select(siteID, PSTL_CODE, rgn_id, rgn_name)
```

Additional data cleaning that adds the Massachusetts sites back in and removes the few sites that are actually in the George's Bank area.

```{r}
sqi_clean <- sqi_0506 %>%
  bind_rows(sqi_2010) %>%
  mutate(rgn_name = 
           case_when(
             PSTL_CODE == "ME" ~ "Maine",
             PSTL_CODE == "RI" ~ "Rhode Island",
             PSTL_CODE == "NY" ~ "New York",
             PSTL_CODE == "CT" ~ "Connecticut",
             PSTL_CODE == "NH" ~ "New Hampshire",
             PSTL_CODE == "MA" ~ "NA"
           )) %>%
  left_join(rgn_data) %>%
  left_join(ma_df, by = "siteID") %>%
  mutate(rgn_id = ifelse(is.na(rgn_id.x), rgn_id.y, rgn_id.x),
         rgn_name = ifelse(rgn_name.x=="NA", rgn_name.y, rgn_name.x)) %>%
  select(-rgn_id.x, -rgn_id.y, -rgn_name.x, -rgn_name.y, -state, -area_km2, -PSTL_CODE.x, -PSTL_CODE.y) %>%
  filter(rgn_name != "Georges Bank") %>%
  as.data.frame()
  # mutate(rgn_name = ifelse(rgn_id == 2, "Massachusetts-Virginian", rgn_name),  ### added this in if we want to turn GB sites to MA
  #        state = ifelse(rgn_id == 2, NA, state),
  #        rgn_id = ifelse(rgn_id == 2, 8, rgn_id))
```

## Run cat.analysis

Use the [`spsurvey`](https://www.rdocumentation.org/packages/spsurvey/versions/3.4) package to run `cat.analysis` and produce a sub-population estimate that incorporates site weights. First we want to see how many sites have a status of `MISSING` to determine if we need to account for them or not.

```{r}
#install.packages("spsurvey")
library(spsurvey)

#remove sites with missing status
sqi_0506 <- sqi_clean %>% 
  filter(Year < 2007,
         NCCA_SQI_STATUS != "",
         NCCA_SQI_STATUS != "Not Assessed")

# Create the required data frames
sites <- sqi_0506 %>%
          select(siteID) %>%
          mutate(use = rep(TRUE, nrow(.)))
subpop <- sqi_0506 %>%
          select(siteID, rgn_name)
design <- sqi_0506 %>%
          select(siteID,
                 wgt = WGT_NCA_56,
                 xcoord = LON_DD,
                 ycoord = LAT_DD)
data <- sqi_0506 %>%
        select(siteID, status = NCCA_SQI_STATUS)

## from this output we only want to grab. Estimate.P is the percent of area (e.g. 98%) for the coastal waters of a subpopulation (e.g. Maine) in a particular category of condition (e.g. Good)
Water_Column_Status_Estimates_0506 <- cat.analysis(sites, subpop, design, data) %>%
  select(rgn_name = Subpopulation, Category, perc = Estimate.P) %>%
  mutate(cat_score = 
      case_when(
        Category == "POOR" ~ 0,
        Category == "FAIR" ~ 50,
        Category == "GOOD" ~ 100
      ),
      year = 2006) 
```

Apply to 2010 data.

```{r}
sqi_2010 <- sqi_clean %>% 
  filter(Year == 2010,
         NCCA_SQI_STATUS != "MISS")

# Create the required data frames
sites <- sqi_2010 %>%
          select(siteID) %>%
          mutate(use = rep(TRUE, nrow(.)))
subpop <- sqi_2010 %>%
          select(siteID, rgn_name)
design <- sqi_2010 %>%
          select(siteID,
                 wgt = WGT_NCCA10,
                 xcoord = LON_DD,
                 ycoord = LAT_DD)
data <- sqi_2010 %>%
        select(siteID, status = NCCA_SQI_STATUS)

## from this output we only want to grab. Estimate.P is the percent of area (e.g. 98%) for the coastal waters of a subpopulation (e.g. Maine) in a particular category of condition (e.g. Good)
Water_Column_Status_Estimates_2010 <- cat.analysis(sites, subpop, design, data) %>%
  select(rgn_name = Subpopulation, Category, perc = Estimate.P) %>%
  mutate(cat_score = 
      case_when(
        Category == "POOR" ~ 0,
        Category == "FAIR" ~ 50,
        Category == "GOOD" ~ 100
      ),
      year = 2010) 
```

## Create layer

Aggregate by region and get WQI scores

```{r}
sqi_rgns <- Water_Column_Status_Estimates_0506 %>%
  rbind(Water_Column_Status_Estimates_2010) %>%
  mutate(score = cat_score * (perc/100)) %>%
  filter(Category != "Total") %>%
  group_by(rgn_name, year) %>%
  summarize(sqi_score = sum(score))

write.csv(sqi_rgns, file = "data/sqi_score_rgns.csv")

ggplot(sqi_rgns, aes(x = year, y = sqi_score, color = rgn_name)) +
  geom_line() +
  theme_bw() +
  labs(x = "Year",
       y = "Score",
       color = "Region")
```

## Gap-filling

The plot has guessed the values between 2006 and 2010 but we need to actually assign these before saving this layer. We will assume a simple linear interpolation between years.

```{r gapfill, eval = F}
df_gf <- sqi_rgns %>%
  complete(year = 2006:2010) %>%
  group_by(rgn_name) %>%
  mutate(score = zoo::na.approx(sqi_score),
         gapfilled = ifelse(is.na(sqi_score), 1, 0))

write.csv(df_gf, file = "data/sqi_score_rgns_gf.csv")
```

## Save layer for toolbox

I need to attach region ID's to each row. I also add the offshore regions 1:4 with NA values for the toolbox to run. 

```{r save_layer, eval = F}
other_rgns <- data.frame(year     = rep(2006:2010, each = 4),
                         rgn_id   = c(1,2,3,4),
                         rgn_name = c("Offshore", "Georges Bank", "Gulf of Maine", "Mid-Atlantic Bight"),
                         score = NA)

out <- df_gf %>%
  left_join(rgn_data) %>%
  select(year, rgn_id, rgn_name, score) %>%
  bind_rows(other_rgns) %>%
  write_csv(file.path(dir_calc, "layers/cw_sqi.csv"))
```

## Citation

Citation: U.S. Environmental Protection Agency. 2016. National Aquatic Resource Surveys. National Coastal Condition Assessment 2010 (data and metadata files). Available from U.S. EPA web page:https://www.epa.gov/national-aquatic-resource-surveys/data-national-aquatic-resource-surveys. Data from the National Aquatic Resource Surveys. Date accessed: 2018-07-31.









