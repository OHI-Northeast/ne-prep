---
title: "Sediment Quality Index data layer"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/ne-prep/src/templates/ohi_hdr.html'
  pdf_document:
    toc: true
---

## Summary

This layer is derived from the [EPA's National Coastal Condition Assessment Sediment Quality Index (SQI) data](https://www.epa.gov/national-aquatic-resource-surveys/ncca), specifically the measurements for 2005/2006 and 2010 time periods.

The EPA measures the Sediment Quality Index for multiple sites throughout the Northeast region. The SQI status for each site are either `GOOD`, `FAIR`, `POOR` or `MISSING`. A score for each OHI-Northeast coastal region is calculated using these SQI values and the site-associated weights. `GOOD` sites are assigned a perfect score (100), `FAIR` sites are assigned a value of 50 and `POOR` sites are assigned a 0. Each site's score is multiplied by it's weight (assigned by the EPA) and then averaged to get final region scores.

Sites with MISSING data are removed.

## Background

> "The National Coastal Condition Assessment (NCCA) is a national coastal monitoring program with rigorous quality assurance protocols and standardized sampling procedures designed to produce national and regional estimates of coastal condition."

> "NCCA evaluates four indices of condition—water quality, sediment quality, benthic community condition, and fish tissue contaminants – to evaluate the ecological condition and recreational potential of coastal waters. Consistent sampling and analytical procedures ensure that the results can be compared across the country and over time."

The SQI is a composite indicator is based on two measures: sediment contaminant concentrations and sediment toxicity.

Assessments have taken place in 2000/2001, 2005/2006, 2010 and 2015. As of this writing, the 2015 data is not available.

### Setup

```{r setup, message = F, warning = F, reslts = 'hide'}
knitr::opts_chunk$set(fig.width = 10, fig.height = 6, fig.path = 'figs/', message = FALSE, warning = FALSE)

source('~/github/ne-prep/src/R/common.R')

library(tidyverse)
```

## Load Data

SQI data was downloaded from [this NCCA data portal](https://www.epa.gov/national-aquatic-resource-surveys/data-national-aquatic-resource-surveys) for the 2010 assessment year. Data for 2005/2006 was not available in a usable format on the portal. Personal communication with folks at the EPA led to retrieval of the 2005/2006 information which was emailed to us on August 27, 2018.

>> "I have attached a file with Sediment Quality Index (NCCA_SQI_STATUS) good/fair/poor values merged with the site information file you have already downloaded."

The data is loaded and filtered for sites in the Northeast region, identified by postal code. The only information we need from the `sites` data is the weighting factor for each site. This will be used later on to properly weight the contribution of each site to the final score.



```{r load_data}
#load 0506 data - this has SQI status AND site info
sqi_0506 <- read.csv("data/NCA0506_SQI+siteinfo.csv") %>%
  filter(SAMPYEAR %in% c(2005,2006),
         NCA_REGION == "East_Coast",
         PSTL_CODE %in% c("MA", "ME", "RI", "NY", "NH", "CT")) %>%
  select(siteID = SITE_ID, LON_DD, LAT_DD, PSTL_CODE, WGT_NCA_56, NCCA_SQI_STATUS) %>%
  mutate(Year = 2006)

#load sqi site info data for 2010
site_info_2010 <- read_csv(file.path(dir_anx, "_raw_data/EPA/assessed_ncca2010_siteinfo.revised.06212016.csv")) %>%
  filter(STATE %in% c("MA", "ME", "RI", "NY", "NH", "CT"),
         NCA_REGION == "East Coast") %>%
  select(SITE_ID, WGT_NCCA10)

#load sqi status data for 2010
sqi_2010 <- read_csv(file.path(dir_anx, "_raw_data/EPA/ncca2010_sediment_indicator_status_revised_06212016.csv")) %>%
  filter(PSTL_CODE %in% c("MA", "ME", "RI", "NY", "NH", "CT"),
         NCCA_REG == "Northeast") %>%
  select(SITE_ID, NCCA_SQI_STATUS, LON_DD, LAT_DD, PSTL_CODE) %>%
  mutate(Year = 2010) %>%
  left_join(site_info_2010) %>%
  rename(siteID = SITE_ID)
```

## Data wrangling

Now assign OHI region names or ids to each of the sites. For the most part, the State in the SQI data is the region, but for Massachusetts we need to be specific about what region the sites belong to. The best way to do this is manually so I use `mapview::mapview()` to identify sites in MA and assign to either Massachusetts-North or Massachusetts-South.

Look first just at sites identified by the `MA` postal code.

```{r ma_sites}
#filter sqi for sites only in MA
ma <- sqi_0506 %>%
  bind_rows(sqi_2010) %>%
  filter(PSTL_CODE == "MA")

#create a simple features (sf) object from the coordinates contained in the dataset
ma_points = st_as_sf(ma, coords = c("LON_DD", "LAT_DD"), 
                 crs = 4326)
#plot
ggplot() +
  geom_sf(data = rgns %>% filter(rgn_id %in% c(7,8)), aes(fill = rgn_id)) +
  geom_sf(data = ma_points, color = 'darkgreen') +
  theme_bw()
```

To assign region ids, try `sf::st_intersect` between the MA sites and the OHI-Northeast regions file already loaded from common.R.
```{r ma_rgns_intersect}
int <- ma_points %>%
  st_transform('+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs') %>%
  st_intersection(rgns)

ggplot() +
  geom_sf(data = rgns %>% filter(rgn_id %in% c(7,8)), aes(fill = rgn_id)) +
  geom_sf(data = int, color = 'darkgreen') +
  theme_bw()
#mapview::mapview(int)
```

It looks like most sites were captured but what points are we missing? We probably didn't get all the sites in the intersection.
```{r missing_ma_sites}
#find sites that are not in the intersection
s <- setdiff(ma_points$siteID, int$siteID)

#limit to just the missing sites
miss <- ma_points %>%
  filter(siteID %in% s)

#use mapviwe to manually explore and then assign region ids
mapview::mapview(miss)

miss_gf <- miss %>%
  data.frame() %>%
  mutate(rgn_id = 
           case_when(
             siteID == "NCCA10-1001" ~ 8,
             siteID == "NCCA10-1008" ~ 8
           )) %>%
  select(-geometry)
```

Take the info from `int` that we want and combine with these missing sites

```{r}
ma_df <- int %>%
  data.frame() %>%
  select(-area_km2, -geometry, -rgn_name) %>%
  bind_rows(miss_gf) %>%
  left_join(rgn_data) %>%
  select(siteID, PSTL_CODE, rgn_id, rgn_name)
```

Additional data cleaning that adds the Massachusetts sites back in and removes the few sites that are actually in the George's Bank area.

```{r clean_sqi_data}
sqi_clean <- sqi_0506 %>%
  bind_rows(sqi_2010) %>%
  mutate(rgn_name = 
           case_when(
             PSTL_CODE == "ME" ~ "Maine",
             PSTL_CODE == "RI" ~ "Rhode Island",
             PSTL_CODE == "NY" ~ "New York",
             PSTL_CODE == "CT" ~ "Connecticut",
             PSTL_CODE == "NH" ~ "New Hampshire",
             PSTL_CODE == "MA" ~ "NA"
           )) %>%
  left_join(rgn_data) %>%
  left_join(ma_df, by = "siteID") %>%
  mutate(rgn_id = ifelse(is.na(rgn_id.x), rgn_id.y, rgn_id.x),
         rgn_name = ifelse(rgn_name.x=="NA", rgn_name.y, rgn_name.x)) %>%
  select(-rgn_id.x, -rgn_id.y, -rgn_name.x, -rgn_name.y, -state, -area_km2, -PSTL_CODE.x, -PSTL_CODE.y) %>%
  filter(rgn_name != "Georges Bank") %>%
  as.data.frame()
```

# Map

Map sample sites status for each year

```{r mapview}

sqi_2006 <- sqi_clean %>% 
  filter(Year == 2006) %>% 
  st_as_sf(coords = c("LON_DD", "LAT_DD"), crs = "+proj=longlat +datum=WGS84 +no_defs")  %>% 
  filter(NCCA_SQI_STATUS != "",
         NCCA_SQI_STATUS != "Not Assessed")
sqi_2010 <- sqi_clean %>% 
  filter(Year == 2010) %>% 
  st_as_sf(coords = c("LON_DD", "LAT_DD"), crs = "+proj=longlat +datum=WGS84 +no_defs") %>% 
  filter(NCCA_SQI_STATUS != "MISS")

mapview::mapview(sqi_2006, zcol = "NCCA_SQI_STATUS", values = c("POOR", "FAIR", "GOOD"), col.regions = c("orange", "forestgreen", "darkred"))
mapview::mapview(sqi_2010, zcol = "NCCA_SQI_STATUS", values = c("POOR", "FAIR", "GOOD"), col.regions = c("orange", "forestgreen", "darkred"))
```


## Run cat.analysis

Use the [`spsurvey`](https://www.rdocumentation.org/packages/spsurvey/versions/3.4) package to run `cat.analysis` and produce a sub-population estimate that incorporates site weights. First we want to see how many sites have a status of `MISSING` to determine if we need to account for them or not.

```{r cat_analysis_0506}
#install.packages("spsurvey")
library(spsurvey)

#remove sites with missing status
sqi_0506 <- sqi_clean %>% 
  filter(Year < 2007,
         NCCA_SQI_STATUS != "",
         NCCA_SQI_STATUS != "Not Assessed")

# Create the required data frames
sites <- sqi_0506 %>%
          select(siteID) %>%
          mutate(use = rep(TRUE, nrow(.)))
subpop <- sqi_0506 %>%
          select(siteID, rgn_name)
design <- sqi_0506 %>%
          select(siteID,
                 wgt = WGT_NCA_56,
                 xcoord = LON_DD,
                 ycoord = LAT_DD)
data <- sqi_0506 %>%
        select(siteID, status = NCCA_SQI_STATUS)

## from this output we only want to grab. Estimate.P is the percent of area (e.g. 98%) for the coastal waters of a subpopulation (e.g. Maine) in a particular category of condition (e.g. Good)
Water_Column_Status_Estimates_0506 <- cat.analysis(sites, subpop, design, data) %>%
  select(rgn_name = Subpopulation, Category, perc = Estimate.P) %>%
  mutate(cat_score = 
      case_when(
        Category == "POOR" ~ 0,
        Category == "FAIR" ~ 50,
        Category == "GOOD" ~ 100
      ),
      year = 2006) 
```

Do the same `cat.analysis` but for 2010 data.

```{r cat_analysis_2010}
sqi_2010 <- sqi_clean %>% 
  filter(Year == 2010,
         NCCA_SQI_STATUS != "MISS")

# Create the required data frames
sites <- sqi_2010 %>%
          select(siteID) %>%
          mutate(use = rep(TRUE, nrow(.)))
subpop <- sqi_2010 %>%
          select(siteID, rgn_name)
design <- sqi_2010 %>%
          select(siteID,
                 wgt = WGT_NCCA10,
                 xcoord = LON_DD,
                 ycoord = LAT_DD)
data <- sqi_2010 %>%
        select(siteID, status = NCCA_SQI_STATUS)

## from this output we only want to grab. Estimate.P is the percent of area (e.g. 98%) for the coastal waters of a subpopulation (e.g. Maine) in a particular category of condition (e.g. Good)
Water_Column_Status_Estimates_2010 <- cat.analysis(sites, subpop, design, data) %>%
  select(rgn_name = Subpopulation, Category, perc = Estimate.P) %>%
  mutate(cat_score = 
      case_when(
        Category == "POOR" ~ 0,
        Category == "FAIR" ~ 50,
        Category == "GOOD" ~ 100
      ),
      year = 2010) 
```

## Create layer

Aggregate by region and get WQI scores

```{r sqi_layer_rgn_scores}
sqi_rgns <- Water_Column_Status_Estimates_0506 %>%
  rbind(Water_Column_Status_Estimates_2010) %>%
  mutate(score = cat_score * (perc/100)) %>%
  filter(Category != "Total") %>%
  group_by(rgn_name, year) %>%
  summarize(sqi_score = sum(score))

write.csv(sqi_rgns, file = "data/sqi_score_rgns.csv")

ggplot(sqi_rgns, aes(x = year, y = sqi_score, color = rgn_name)) +
  geom_line() +
  theme_bw() +
  labs(x = "Year",
       y = "Score",
       color = "Region")
```

## Gap-filling

The plot has guessed the values between 2006 and 2010 but we need to actually assign these before saving this layer. We will assume a simple linear interpolation between years.

```{r gapfill}
df_gf <- sqi_rgns %>%
  complete(year = 2006:2010) %>%
  group_by(rgn_name) %>%
  mutate(score = zoo::na.approx(sqi_score),
         gapfilled = ifelse(is.na(sqi_score), 1, 0))

write.csv(df_gf, file = "data/sqi_score_rgns_gf.csv")
```

## Save layer for toolbox

I need to attach region ID's to each row. I also add the offshore regions 1:4 with NA values for the toolbox to run. 

```{r save_layer}
other_rgns <- data.frame(year     = rep(2006:2010, each = 4),
                         rgn_id   = c(1,2,3,4),
                         rgn_name = c("Offshore", "Georges Bank", "Gulf of Maine", "Mid-Atlantic Bight"),
                         score = NA)

df_gf %>%
  left_join(rgn_data) %>%
  select(year, rgn_id, rgn_name, score) %>%
  bind_rows(other_rgns) %>%
  write_csv(file.path(dir_calc, "layers/cw_sqi.csv"))
```

Save as a pressure layer as well (inverse)

```{r}
df_gf %>%
  left_join(rgn_data) %>%
  mutate(score = 1-score/100) %>%
  select(year, rgn_id, rgn_name, score) %>%
  bind_rows(other_rgns) %>%
  write_csv(file.path(dir_calc, "layers/prs_sqi.csv"))
```

## Citation

Citation: U.S. Environmental Protection Agency. 2016. National Aquatic Resource Surveys. National Coastal Condition Assessment 2010 (data and metadata files). Available from U.S. EPA web page:https://www.epa.gov/national-aquatic-resource-surveys/data-national-aquatic-resource-surveys. Data from the National Aquatic Resource Surveys. Date accessed: 2018-07-31.









